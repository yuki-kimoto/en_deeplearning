<h2> Introduction to Perl Deep Learning AI </h2>

Perl Deep Learning AI Primer is a course where you can learn the basics necessary for deep learning with Perl sample code. Deep learning, also known as deep learning, is a field of machine learning that can achieve high accuracy. We are devising so that you can learn the mathematical knowledge necessary for deep learning only with the basic knowledge of mathematics that you are learning in high school mathematics. It is also characterized by introducing as few mathematical formulas as possible and focusing on programmatic algorithms.

Since it is written only in Perl, it is a feature of this site that you can start learning without preparing a dedicated library or learning. With Perl installed, you can start learning deep learning right away.

For those who want to use deep learning AI for practical image recognition, pattern recognition, and voice recognition, we also introduce Perl's deep learning library "AI :: NXNet".

<ul>
  <li> <a href="https://www.youtube.com/watch?v=dTKY0kor50A"> Video introduction</a> </li>
</ul>

<h3> What is deep learning? </H3>

<ul>
  <li> <a href="/blog/20210920074017.html"> What is deep learning?</a> </li>
</ul>

<h3> Building a Perl environment for learning deep learning </h3>

Install Perl to learn deep learning. Compatible with Windows, Mac and Linux / UNIX.

<ul>
  <li> <a href="https://en.perlzemi.com/blog/20180820153471.html"> Perl installation</a> </li>
</ul>

<h3> Perl's deep learning library </h3>

Deep Learning Introducing Perl's deep learning library "AI :: NXNet" for those who want to perform image recognition, pattern recognition, and voice recognition in practice using AI.

<ul>
  <li> <a href="/blog/20201118093000.html"> Perl's deep learning library --AI :: MXNet</a> </li>
</ul>

<h3> Basic knowledge </h3>

Learn the basics of deep learning.

<ul>
  <li> <a href="/blog/20200905120907.html"> Representing the number of neurons in the hidden layer</a> </li>
  <li> <a href="/blog/20200904120907.html"> The unit called epoch means to go around the training data</a> </li>
  <li> <a href="/blog/20200830120907.html"> What is batch size?-Online learning, mini-batch learning, batch learning</a> </li>
  <li> <a href="/blog/20200923123308.html"> What is the learning rate?</a> </li>
  <li> <a href="/blog/20200921123308.html"> What is a gradient?</a> </li>
</ul>

<h3> Input processing </h3>

<ul>
  <li> <a href="/blog/20200907120907.html"> Read MINIST image information</a> </li>
  <li> <a href="/blog/20200909120907.html"> Read MINIST label information</a> </li>
  <li> <a href="/blog/20200906120907.html"> Randomly shuffle training data</a> </li>
</ul>

<h3> Weights and biases </h3>

<ul>
  <li> <a href="/blog/20201016143424.html"> What is bias?</a> </li>
  <li> <a href="/blog/20201015143424.html"> What is a weight?</a> </li>
  <li> <a href="/blog/20200311113241.html"> How to set the initial values ​​of weight and bias of each layer</a> </li>
  <li> <a href="/blog/20201005144439.html"> Find random numbers that follow a normal distribution</a> </li>
  <li> <a href="/blog/20201007144439.html"> Initial value of Xavier</a> </li>
  <li> <a href="/blog/20201006144439.html"> Initial value of He</a> </li>
</ul>

<h3> Mathematics used in deep learning </h3>

<h4> Input / output </h4>

<ul>
  <li> <a href="/blog/20200302113052.html"> Calculations in hidden layers-convert m inputs to n outputs</a> </li>
  <li> <a href="/blog/20200306113052.html"> Calculations in the output layer</a> </li>
  <li> <a href="/blog/20200915121719.html"> Calculation process to get the final output from the initial input by deep learning</a> </li>
</ul>

<h4> Vector </h4>

<ul>
  <li> <a href="/blog/20200913103640.html"> Find the sum of the vectors</a> </li>
  <li> <a href="/blog/20200828120907.html"> Find the difference between the vectors</a> </li>
  <li> <a href="/blog/20200924123308.html"> Calculation of vector inner product</a> </li>
</ul>

<h4> Matrix </h4>

<ul>
  <li> <a href="/blog/20200928161518.html"> What is a matrix</a> </li>
  <li> <a href="/blog/20200929161518.html"> Create a column priority matrix</a> </li>
  <li> <a href="/blog/20200912123308.html"> Find the sum of matrices</a> </li>
  <li> <a href="/blog/20200829120907.html"> Find the difference in the matrix</a> </li>
  <li> <a href="/blog/20200914103640.html"> Matrix multiplication calculation</a> </li>
  <li> <a href="/blog/20200917123308.html"> Find the transposed matrix</a> </li>
</ul>

<h4> Differentiation </h4>

<ul>
  <li> <a href="/blog/20201020085300.html"> What is tilting?</a> </li>
  <li> <a href="/blog/20201021085550.html"> How to find the slope in the case of a multi-stage function --Differentiation of synthetic function</a> </li>
  <li> <a href="/blog/20200919123308.html"> What is a derivative</a> </li>
  <li> <a href="/blog/20201026095954.html"> Inverse error propagation method --Backpropagation Start writing</a> </li>
</ul>

<h3> Activation function </h3>

<ul>
  <li> <a href="/blog/20200902120907.html"> What is the activation function</a> </li>
  <li> <a href="/blog/20200903120907.html"> Sigmoid function</a> </li>
  <li> <a href="/blog/20200920123308.html"> Derivative of the sigmoid function</a> </li>
  <li> <a href="/blog/20200911102242.html"> ReLU function</a> </li>
  <li> <a href="/blog/20201001161518.html"> Derivatives of the ReLU function</a> </li>
  <li> <a href="/blog/20201019123741.html"> tanh function</a> </li>
  <li> <a href="/blog/20201018123741.html"> Derivative of the tanh function</a> </li>
</ul>

<h3> Output layer </h3>

<ul>
  <li> <a href="/blog/20200916101844.html"> Probability of expected output</a> </li>
  <li> <a href="/blog/20201002161518.html"> softmax function</a> </li>
  <li> <a href="/blog/20200927161518.html"> softmax Cross entropy derivative</a> </li>
</ul>

<h3> Loss function </h3>

<ul>
  <li> <a href="/blog/20200901120907.html"> What is a loss function</a> </li>
  <li> <a href="/blog/20200910120907.html"> Find the sum of squares error</a> </li>
  <li> <a href="/blog/20200831120907.html"> Cross entropy error</a> </li>
</ul>

<h3> Update weights and biases </h3>

<ul>
  <li> <a href="/blog/20201023083657.html"> What is the parameter update optimization algorithm?</a> </li>
  <li> <a href="/blog/20201017123741.html"> Stochastic Gradient Descent (SGD)-Update Weight and Bias Parameters</a> </li>
  <li> <a href="/blog/20201022083657.html"> Adam --Improved SGD</a> </li>
</ul>

<h3> Perl + Handwriting recognition with deep learning </h3>

<ul>
  <li> <a href="/blog/20200908120907.html"> Perl + Handwriting recognition with deep learning</a> </li>
  <li> <a href="/blog/20200926161518.html"> MNIST handwriting recognition deep learning written in pure Perl</a> </li>
</ul>

<h3> Accelerate deep learning using SPVM </h3>

<ul>
  <li> <a href="/blog/20210510142804.html"> Accelerate deep learning using SPVM</a> </li>
</ul>

<h3> Perl Deep Learning AI Introductory Related Course </h3>

Introducing related courses on Perl deep learning AI introductory.

<h4> Introduction to Perl Pro Blog Ramming </h4>

Learn the basics of Perl programming here.

<ul>
  <li> <a href="https://en.perlzemi.com/"> Perl Seminar-Introduction to Perl Programming</a> </li>
</ul>

<h4> Deep learning acceleration technology </h4>

Click here to learn the technology for accelerating deep learning.

<ul>
  <li> <a href="https://en.c.perlzemi.com/"> Introduction to C for Perl XS users</a> </li>
  <li> <a href="https://en.bind.perlzemi.com/"> Getting Started with Perl Bindings-Calling C / C ++ / Cuda from Perl</a> </li>
</ul>

<h4> Data analysis </h4>

Data analysis is a direct learning AIAlthough not relevant, it is misunderstood by the public and introduced as highly relevant. Please note that the words "big data" and "AI" are distributed on the surface of information as buzzwords, and there is a high possibility of investment fraud. I hope you know the actual data analysis and resolve the misunderstanding.

<ul>
  <li> <a href="https://en.datascience.perlzemi.com/"> Introduction to Data Analysis</a> </li>
</ul>

<h4> Deep learning questions </h4>

There is a members-only Perl Club Forum where you can interact with your peers and ask deep learning questions. You can also use Twitter's reply / direct message and Youtube's comment section.

<ul>
  <li> <a href="https://perlclub.net/forum"> Perl Club Forum</a>
  <li> <a href="https://twitter.com/perlzemi"> Twitter</a>
  <li> <a href="https://www.youtube.com/channel/UCbeAS6ZXpSKqkzb-Nykb0ZQ"> Youtube</a>
</ul>