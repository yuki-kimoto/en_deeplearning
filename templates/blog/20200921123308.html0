<h2>勾配(こうばい)とは</h2>

ディープラーニングにおける、勾配(こうばい)とは、バイアスの各パラメータに対する損失関数の傾きを求めて、ベクトルとして一つにまとめたものです。あるいは、重み各列の各パラメーターに対する損失関数の傾きを求めて、ベクトルとして一つにまとめたものです。

<h3>バイアスパラメーターの場合</h3>

n層のb1を0.01増やしたとき、損失関数の値が0.002増えたとすると、傾きは「2 = 0.002/0.001」です。

n層のb2を0.01増やしたとき、損失関数の値が0.005増えたとすると、傾きは「5 = 0.005/0.001」です。

n層のb3を0.01増やしたとき、損失関数の値が0.003増えたとすると、傾きは「3 = 0.003/0.001」です。

勾配は傾きを求めてベクトルとして一つにまとめたものなので「[2, 5, 3]」です。

アルゴリズムとして考える場合は、個々の傾きだけを考えるので十分です。

<h3>重みパラメーターの場合</h3>

<b>1列目</b>

n層のw11を0.01増やしたとき、損失関数の値が0.002増えたとすると、傾きは「2 = 0.002/0.001」です。

n層のw21を0.01増やしたとき、損失関数の値が0.005増えたとすると、傾きは「5 = 0.005/0.001」です。

n層のw31を0.01増やしたとき、損失関数の値が0.003増えたとすると、傾きは「3 = 0.003/0.001」です。

勾配は傾きを求めてベクトルとして一つにまとめたものなので「[2, 5, 3]」です。

<b>2列目</b>

n層のw12を0.01増やしたとき、損失関数の値が0.006増えたとすると、傾きは「6 = 0.006/0.001」です。

n層のw22を0.01増やしたとき、損失関数の値が0.004増えたとすると、傾きは「4 = 0.004/0.001」です。

n層のw32を0.01増やしたとき、損失関数の値が0.002増えたとすると、傾きは「2 = 0.002/0.001」です。

勾配は傾きを求めてベクトルとして一つにまとめたものなので「[6, 4, 2]」です。

追加知識として、それぞれの勾配を縦に並べて、つなげた行列をヤコビ行列と呼びます。

<pre>
2 6
5 4
3 2
</pre>

アルゴリズムとして考える場合は、個々の傾きだけを考えるので十分です。勾配やヤコビ行列をアルゴリズムの中で意識する必要はありません。単に配列として意識してください。
