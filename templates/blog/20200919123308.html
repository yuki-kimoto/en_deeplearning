<h2>導関数とは</h2>

導関数とは、関数の微分のことです。関数の微分とは、入力の微小な変化量に対する、出力の変化量の比をとり、微小変化を極限まで0に近づけたときの値です。

<pre>
微分 = 出力の変化量 / 入力の微小な変化量(極限まで0に近づける)
</pre>

たとえば、0.5という入力を考えます。

0.5から、微少量0.001を増やします。0.5に対する出力はfunc(0.5)です。「0.5 + 0.001」に対する出力はfunc(0.5 + 0.001)です。

入力の微小変化は「0.001」です。これに対する出力の変化は「func(0.5 + 0.001) - func(0.5)」です。

微分は「func(0.5 + 0.001) - func(0.5) / 0.001」で、0.001を極限まで0に近づけた値です。

特定の入力に対する微分は、傾きとも呼ばれます。入力の微小変化に対して、出力の変化量が大きい場合は、傾きは大きくなります。

<h3>ディープラーニングにおける導関数が使用される場所</h3>

ディープラーニングにおいては、導関数がでてきた場合は、傾きを表すものだと考えください。

隠れ層の重みとバイアスのパラメーターが、入力となり、<a href="/blog/20200901120907.html">損失関数</a>が出力となります。

損失関数は誤差の指標となっており、誤差を小さくするように、重みとバイアスのパラメーターを調整します。

<a href="/blog/20200922123308.html">バックプロパゲーション</a>と呼ばれるアルゴリズムを使い「損失関数の値を減少させる向きの重みの傾きの組」と「損失関数の値を減少させる向きのバイアスの傾きの組」を求め、<a href="/blog/20200923123308.html">学習率</a>を考慮して、「現在の重みの組」と「現在のバイアスの組」から引き算します。正規化という手法を使う場合は、正規化も考慮にいれて引き算します。
